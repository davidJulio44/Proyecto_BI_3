{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Crypto BI — Análisis Completo de Criptomonedas\n",
    "\n",
    "**Proyecto:** Business Intelligence 3  \n",
    "**Autores:** Juan David Reyes Cure, Julio David Suarez Olaya, Adriana Michelle Diaz Suarez\n",
    "\n",
    "## Pipeline de Análisis\n",
    "\n",
    "Este notebook ejecuta el pipeline completo de análisis:\n",
    "\n",
    "1. **📥 Carga de Datos:** Dataset limpio con features derivadas\n",
    "2. **🔍 Clustering:** Segmentación con K-Means, DBSCAN y Agglomerative\n",
    "3. **📈 Series Temporales ARIMA:** Modelos estadísticos clásicos\n",
    "4. **🧠 Redes Neuronales RNN:** Modelos LSTM/GRU con TensorFlow\n",
    "5. **📊 Evaluación:** Métricas MAE, RMSE y Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Imports de módulos propios (en la misma carpeta scripts/)\n",
    "from clustering import kmeans_cluster, dbscan_cluster, agglomerative_cluster\n",
    "from models_arima import train_arima, forecast_arima\n",
    "from models_rnn import train_rnn\n",
    "\n",
    "# Configuración de visualización\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Cargar datos\n",
    "DATA = Path('../data/crypto_clean_BTC_ETH_BNB.csv')\n",
    "df = pd.read_csv(DATA, parse_dates=['date'])\n",
    "\n",
    "print(f\"✅ Datos cargados: {len(df)} filas, {len(df.columns)} columnas\")\n",
    "print(f\"📅 Rango: {df['date'].min()} a {df['date'].max()}\")\n",
    "print(f\"💰 Criptomonedas: {', '.join(df['symbol'].unique())}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Clustering: Segmentación de Patrones de Mercado\n",
    "\n",
    "Aplicamos 3 familias de algoritmos de clustering:\n",
    "\n",
    "### 1. **K-Means** (Particionante)\n",
    "- Divide los datos en k grupos predefinidos\n",
    "- Minimiza la distancia intra-cluster\n",
    "\n",
    "### 2. **DBSCAN** (Basado en Densidad)\n",
    "- Detecta clusters de forma arbitraria\n",
    "- Identifica outliers (ruido) automáticamente\n",
    "\n",
    "### 3. **Agglomerative** (Jerárquico)\n",
    "- Clustering bottom-up aglomerativo\n",
    "- Construye jerarquía de clusters\n",
    "\n",
    "**Features utilizadas:** `daily_return`, `roll_vol_30d`  \n",
    "**Métrica de evaluación:** Silhouette Score (rango -1 a 1, mayor es mejor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar features para clustering\n",
    "features = ['daily_return', 'roll_vol_30d']\n",
    "dropna_df = df.dropna(subset=features)\n",
    "\n",
    "print(f\"📊 Datos para clustering: {len(dropna_df)} observaciones\")\n",
    "print(f\"🎯 Features: {features}\\n\")\n",
    "\n",
    "# 1. K-Means (Particionante)\n",
    "print(\"1️⃣ K-Means Clustering...\")\n",
    "km_labels, km_pipe, km_sil = kmeans_cluster(dropna_df, features, n_clusters=3)\n",
    "print(f\"   Silhouette Score: {km_sil:.4f}\")\n",
    "\n",
    "# 2. DBSCAN (Basado en densidad)\n",
    "print(\"\\n2️⃣ DBSCAN Clustering...\")\n",
    "db_labels, db_pipe, db_sil = dbscan_cluster(dropna_df, features, eps=0.3, min_samples=20)\n",
    "print(f\"   Silhouette Score: {db_sil:.4f}\")\n",
    "print(f\"   Outliers detectados: {(db_labels['label'] == -1).sum()}\")\n",
    "\n",
    "# 3. Agglomerative (Jerárquico)\n",
    "print(\"\\n3️⃣ Agglomerative Clustering...\")\n",
    "ag_labels, ag_pipe, ag_sil = agglomerative_cluster(dropna_df, features, n_clusters=3)\n",
    "print(f\"   Silhouette Score: {ag_sil:.4f}\")\n",
    "\n",
    "# Resumen comparativo\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📊 RESUMEN COMPARATIVO\")\n",
    "print(\"=\"*50)\n",
    "results = pd.DataFrame({\n",
    "    'Algoritmo': ['K-Means', 'DBSCAN', 'Agglomerative'],\n",
    "    'Silhouette Score': [km_sil, db_sil, ag_sil],\n",
    "    'N° Clusters': [3, len(db_labels['label'].unique()) - (1 if -1 in db_labels['label'].values else 0), 3]\n",
    "})\n",
    "print(results.to_string(index=False))\n",
    "print(f\"\\n🏆 Mejor algoritmo: {results.loc[results['Silhouette Score'].idxmax(), 'Algoritmo']}\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📈 Modelo ARIMA: Predicción de Precios (BTC)\n",
    "\n",
    "**ARIMA** (AutoRegressive Integrated Moving Average) es un modelo estadístico clásico para series temporales.\n",
    "\n",
    "### Características:\n",
    "- **AR (p):** Componente autoregresivo (valores pasados)\n",
    "- **I (d):** Diferenciación para estacionariedad\n",
    "- **MA (q):** Media móvil de errores pasados\n",
    "\n",
    "### Configuración:\n",
    "- **Split:** 80% train / 20% test (validación temporal)\n",
    "- **Order:** (1,1,1) - configurable\n",
    "- **Métricas:** MAE (Mean Absolute Error) y RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar datos de BTC\n",
    "btc = df[df['symbol']=='BTC'][['date','price_usd']].copy()\n",
    "\n",
    "print(f\"📊 Datos BTC: {len(btc)} observaciones\")\n",
    "print(f\"📅 Periodo: {btc['date'].min()} a {btc['date'].max()}\")\n",
    "print(f\"\\n⏳ Entrenando modelo ARIMA (puede tardar 1-2 minutos)...\\n\")\n",
    "\n",
    "# Entrenar modelo ARIMA\n",
    "res, y_train, y_test, preds, arima_metrics = train_arima(\n",
    "    btc, \n",
    "    date_col='date', \n",
    "    target_col='price_usd',\n",
    "    order=(1,1,1),  # (p,d,q)\n",
    "    train_ratio=0.8\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"=\"*50)\n",
    "print(\"📊 RESULTADOS ARIMA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE (Mean Absolute Error):  ${arima_metrics['MAE']:,.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): ${arima_metrics['RMSE']:,.2f}\")\n",
    "print(f\"\\n📈 Train size: {len(y_train)} días\")\n",
    "print(f\"📉 Test size:  {len(y_test)} días\")\n",
    "\n",
    "# Visualización simple\n",
    "print(f\"\\n💰 Precio real promedio (test): ${y_test.mean():,.2f}\")\n",
    "print(f\"🎯 Predicción promedio: ${preds.mean():,.2f}\")\n",
    "print(f\"📊 Error promedio: ${arima_metrics['MAE']:,.2f} ({(arima_metrics['MAE']/y_test.mean()*100):.2f}%)\")\n",
    "\n",
    "arima_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧠 Modelo RNN: Redes Neuronales Recurrentes (BTC)\n",
    "\n",
    "**LSTM** (Long Short-Term Memory) es una arquitectura de red neuronal recurrente diseñada para aprender dependencias a largo plazo.\n",
    "\n",
    "### Características:\n",
    "- **Lookback Window:** 30 días (usa 30 valores pasados para predecir el siguiente)\n",
    "- **Arquitectura:** LSTM(64 unidades) → Dense(1)\n",
    "- **Normalización:** MinMaxScaler (0-1)\n",
    "- **Early Stopping:** Evita overfitting automáticamente\n",
    "\n",
    "### Ventajas sobre ARIMA:\n",
    "- ✅ Captura patrones no lineales\n",
    "- ✅ Memoria a largo plazo\n",
    "- ✅ No requiere estacionariedad\n",
    "\n",
    "**Nota:** Usamos `epochs=5` para demostración rápida (producción: 50-100 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧠 Entrenando modelo LSTM...\")\n",
    "print(\"⏳ Esto puede tardar 2-3 minutos dependiendo del hardware\\n\")\n",
    "\n",
    "# Entrenar modelo RNN (LSTM)\n",
    "model, scaler, rnn_metrics = train_rnn(\n",
    "    btc, \n",
    "    date_col='date', \n",
    "    target_col='price_usd', \n",
    "    model_type='LSTM',    # Alternativa: 'GRU'\n",
    "    lookback=30,          # Ventana de 30 días\n",
    "    epochs=5,             # Bajo para demo (producción: 50-100)\n",
    "    batch_size=32,\n",
    "    train_ratio=0.8\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📊 RESULTADOS LSTM\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE (Mean Absolute Error):  ${rnn_metrics['MAE']:,.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): ${rnn_metrics['RMSE']:,.2f}\")\n",
    "print(f\"\\n🏆 Arquitectura: LSTM(64) → Dense(1)\")\n",
    "print(f\"📊 Lookback window: 30 días\")\n",
    "\n",
    "# Comparación con ARIMA\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"📊 COMPARACIÓN: ARIMA vs LSTM\")\n",
    "print(\"=\"*50)\n",
    "comparison = pd.DataFrame({\n",
    "    'Modelo': ['ARIMA', 'LSTM'],\n",
    "    'MAE': [arima_metrics['MAE'], rnn_metrics['MAE']],\n",
    "    'RMSE': [arima_metrics['RMSE'], rnn_metrics['RMSE']]\n",
    "})\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "best_model = 'ARIMA' if arima_metrics['MAE'] < rnn_metrics['MAE'] else 'LSTM'\n",
    "print(f\"\\n🏆 Mejor modelo (menor MAE): {best_model}\")\n",
    "\n",
    "rnn_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ecf79",
   "metadata": {},
   "source": [
    "## 📊 Visualización de Clusters\n",
    "\n",
    "Graficamos los clusters en el espacio de features (daily_return vs roll_vol_30d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db354be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para visualización\n",
    "plot_df = dropna_df[features].copy()\n",
    "plot_df['KMeans'] = km_labels['label'].values\n",
    "plot_df['DBSCAN'] = db_labels['label'].values\n",
    "plot_df['Agglomerative'] = ag_labels['label'].values\n",
    "\n",
    "# Crear subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# K-Means\n",
    "scatter1 = axes[0].scatter(plot_df['daily_return'], plot_df['roll_vol_30d'], \n",
    "                           c=plot_df['KMeans'], cmap='viridis', alpha=0.6, s=20)\n",
    "axes[0].set_title(f'K-Means\\nSilhouette: {km_sil:.4f}', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Daily Return')\n",
    "axes[0].set_ylabel('Rolling Volatility 30D')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# DBSCAN\n",
    "scatter2 = axes[1].scatter(plot_df['daily_return'], plot_df['roll_vol_30d'], \n",
    "                           c=plot_df['DBSCAN'], cmap='viridis', alpha=0.6, s=20)\n",
    "axes[1].set_title(f'DBSCAN\\nSilhouette: {db_sil:.4f}', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Daily Return')\n",
    "axes[1].set_ylabel('Rolling Volatility 30D')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster (-1=Outlier)')\n",
    "\n",
    "# Agglomerative\n",
    "scatter3 = axes[2].scatter(plot_df['daily_return'], plot_df['roll_vol_30d'], \n",
    "                           c=plot_df['Agglomerative'], cmap='viridis', alpha=0.6, s=20)\n",
    "axes[2].set_title(f'Agglomerative\\nSilhouette: {ag_sil:.4f}', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Daily Return')\n",
    "axes[2].set_ylabel('Rolling Volatility 30D')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter3, ax=axes[2], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Visualización completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ef69e",
   "metadata": {},
   "source": [
    "## 📝 Conclusiones y Resultados Finales\n",
    "\n",
    "### 🎯 Resumen del Análisis\n",
    "\n",
    "Este notebook demostró la implementación completa de técnicas avanzadas de Business Intelligence aplicadas a criptomonedas:\n",
    "\n",
    "#### 1. **Clustering**\n",
    "- ✅ Implementados 3 algoritmos: K-Means, DBSCAN, Agglomerative\n",
    "- ✅ Evaluación con Silhouette Score\n",
    "- ✅ Identificación de patrones de mercado y outliers\n",
    "\n",
    "#### 2. **Series Temporales - ARIMA**\n",
    "- ✅ Modelo estadístico clásico\n",
    "- ✅ Validación temporal (80/20)\n",
    "- ✅ Métricas: MAE y RMSE\n",
    "\n",
    "#### 3. **Redes Neuronales - LSTM**\n",
    "- ✅ Deep Learning con TensorFlow/Keras\n",
    "- ✅ Arquitectura: LSTM(64) → Dense(1)\n",
    "- ✅ Early Stopping para prevenir overfitting\n",
    "\n",
    "### 📊 Cumplimiento de Objetivos Sprint 2\n",
    "\n",
    "| Objetivo | Estado |\n",
    "|----------|--------|\n",
    "| Implementar análisis de series temporales | ✅ |\n",
    "| Identificar patrones y tendencias | ✅ |\n",
    "| Clusterización (densidad, particionante, jerárquico) | ✅ |\n",
    "| Modelos de predicción (ARIMA, LSTM, GRU) | ✅ |\n",
    "| Métricas de evaluación | ✅ |\n",
    "| Módulos backend | ✅ |\n",
    "| Notebook ejecutado | ✅ |\n",
    "\n",
    "### 🚀 Próximos Pasos (Sprint 3)\n",
    "- Dashboard interactivo con Streamlit\n",
    "- API REST con FastAPI\n",
    "- Backtesting y walk-forward validation\n",
    "- Grid search para optimización de hiperparámetros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
