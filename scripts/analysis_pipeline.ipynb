{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š Crypto BI â€” AnÃ¡lisis Completo de Criptomonedas\n",
    "\n",
    "**Proyecto:** Business Intelligence 3  \n",
    "**Autores:** Juan David Reyes Cure, Julio David Suarez Olaya, Adriana Michelle Diaz Suarez\n",
    "\n",
    "## Pipeline de AnÃ¡lisis\n",
    "\n",
    "Este notebook ejecuta el pipeline completo de anÃ¡lisis:\n",
    "\n",
    "1. **ğŸ“¥ Carga de Datos:** Dataset limpio con features derivadas\n",
    "2. **ğŸ” Clustering:** SegmentaciÃ³n con K-Means, DBSCAN y Agglomerative\n",
    "3. **ğŸ“ˆ Series Temporales ARIMA:** Modelos estadÃ­sticos clÃ¡sicos\n",
    "4. **ğŸ§  Redes Neuronales RNN:** Modelos LSTM/GRU con TensorFlow\n",
    "5. **ğŸ“Š EvaluaciÃ³n:** MÃ©tricas MAE, RMSE y Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Imports de mÃ³dulos propios (en la misma carpeta scripts/)\n",
    "from clustering import kmeans_cluster, dbscan_cluster, agglomerative_cluster\n",
    "from models_arima import train_arima, forecast_arima\n",
    "from models_rnn import train_rnn\n",
    "\n",
    "# ConfiguraciÃ³n de visualizaciÃ³n\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Cargar datos\n",
    "DATA = Path('../data/crypto_clean_BTC_ETH_BNB.csv')\n",
    "df = pd.read_csv(DATA, parse_dates=['date'])\n",
    "\n",
    "print(f\"âœ… Datos cargados: {len(df)} filas, {len(df.columns)} columnas\")\n",
    "print(f\"ğŸ“… Rango: {df['date'].min()} a {df['date'].max()}\")\n",
    "print(f\"ğŸ’° Criptomonedas: {', '.join(df['symbol'].unique())}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Clustering: SegmentaciÃ³n de Patrones de Mercado\n",
    "\n",
    "Aplicamos 3 familias de algoritmos de clustering:\n",
    "\n",
    "### 1. **K-Means** (Particionante)\n",
    "- Divide los datos en k grupos predefinidos\n",
    "- Minimiza la distancia intra-cluster\n",
    "\n",
    "### 2. **DBSCAN** (Basado en Densidad)\n",
    "- Detecta clusters de forma arbitraria\n",
    "- Identifica outliers (ruido) automÃ¡ticamente\n",
    "\n",
    "### 3. **Agglomerative** (JerÃ¡rquico)\n",
    "- Clustering bottom-up aglomerativo\n",
    "- Construye jerarquÃ­a de clusters\n",
    "\n",
    "**Features utilizadas:** `daily_return`, `roll_vol_30d`  \n",
    "**MÃ©trica de evaluaciÃ³n:** Silhouette Score (rango -1 a 1, mayor es mejor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar features para clustering\n",
    "features = ['daily_return', 'roll_vol_30d']\n",
    "dropna_df = df.dropna(subset=features)\n",
    "\n",
    "print(f\"ğŸ“Š Datos para clustering: {len(dropna_df)} observaciones\")\n",
    "print(f\"ğŸ¯ Features: {features}\\n\")\n",
    "\n",
    "# 1. K-Means (Particionante)\n",
    "print(\"1ï¸âƒ£ K-Means Clustering...\")\n",
    "km_labels, km_pipe, km_sil = kmeans_cluster(dropna_df, features, n_clusters=3)\n",
    "print(f\"   Silhouette Score: {km_sil:.4f}\")\n",
    "\n",
    "# 2. DBSCAN (Basado en densidad)\n",
    "print(\"\\n2ï¸âƒ£ DBSCAN Clustering...\")\n",
    "db_labels, db_pipe, db_sil = dbscan_cluster(dropna_df, features, eps=0.3, min_samples=20)\n",
    "print(f\"   Silhouette Score: {db_sil:.4f}\")\n",
    "print(f\"   Outliers detectados: {(db_labels['label'] == -1).sum()}\")\n",
    "\n",
    "# 3. Agglomerative (JerÃ¡rquico)\n",
    "print(\"\\n3ï¸âƒ£ Agglomerative Clustering...\")\n",
    "ag_labels, ag_pipe, ag_sil = agglomerative_cluster(dropna_df, features, n_clusters=3)\n",
    "print(f\"   Silhouette Score: {ag_sil:.4f}\")\n",
    "\n",
    "# Resumen comparativo\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š RESUMEN COMPARATIVO\")\n",
    "print(\"=\"*50)\n",
    "results = pd.DataFrame({\n",
    "    'Algoritmo': ['K-Means', 'DBSCAN', 'Agglomerative'],\n",
    "    'Silhouette Score': [km_sil, db_sil, ag_sil],\n",
    "    'NÂ° Clusters': [3, len(db_labels['label'].unique()) - (1 if -1 in db_labels['label'].values else 0), 3]\n",
    "})\n",
    "print(results.to_string(index=False))\n",
    "print(f\"\\nğŸ† Mejor algoritmo: {results.loc[results['Silhouette Score'].idxmax(), 'Algoritmo']}\")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Modelo ARIMA: PredicciÃ³n de Precios (BTC)\n",
    "\n",
    "**ARIMA** (AutoRegressive Integrated Moving Average) es un modelo estadÃ­stico clÃ¡sico para series temporales.\n",
    "\n",
    "### CaracterÃ­sticas:\n",
    "- **AR (p):** Componente autoregresivo (valores pasados)\n",
    "- **I (d):** DiferenciaciÃ³n para estacionariedad\n",
    "- **MA (q):** Media mÃ³vil de errores pasados\n",
    "\n",
    "### ConfiguraciÃ³n:\n",
    "- **Split:** 80% train / 20% test (validaciÃ³n temporal)\n",
    "- **Order:** (1,1,1) - configurable\n",
    "- **MÃ©tricas:** MAE (Mean Absolute Error) y RMSE (Root Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar datos de BTC\n",
    "btc = df[df['symbol']=='BTC'][['date','price_usd']].copy()\n",
    "\n",
    "print(f\"ğŸ“Š Datos BTC: {len(btc)} observaciones\")\n",
    "print(f\"ğŸ“… Periodo: {btc['date'].min()} a {btc['date'].max()}\")\n",
    "print(f\"\\nâ³ Entrenando modelo ARIMA (puede tardar 1-2 minutos)...\\n\")\n",
    "\n",
    "# Entrenar modelo ARIMA\n",
    "res, y_train, y_test, preds, arima_metrics = train_arima(\n",
    "    btc, \n",
    "    date_col='date', \n",
    "    target_col='price_usd',\n",
    "    order=(1,1,1),  # (p,d,q)\n",
    "    train_ratio=0.8\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"=\"*50)\n",
    "print(\"ğŸ“Š RESULTADOS ARIMA\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE (Mean Absolute Error):  ${arima_metrics['MAE']:,.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): ${arima_metrics['RMSE']:,.2f}\")\n",
    "print(f\"\\nğŸ“ˆ Train size: {len(y_train)} dÃ­as\")\n",
    "print(f\"ğŸ“‰ Test size:  {len(y_test)} dÃ­as\")\n",
    "\n",
    "# VisualizaciÃ³n simple\n",
    "print(f\"\\nğŸ’° Precio real promedio (test): ${y_test.mean():,.2f}\")\n",
    "print(f\"ğŸ¯ PredicciÃ³n promedio: ${preds.mean():,.2f}\")\n",
    "print(f\"ğŸ“Š Error promedio: ${arima_metrics['MAE']:,.2f} ({(arima_metrics['MAE']/y_test.mean()*100):.2f}%)\")\n",
    "\n",
    "arima_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Modelo RNN: Redes Neuronales Recurrentes (BTC)\n",
    "\n",
    "**LSTM** (Long Short-Term Memory) es una arquitectura de red neuronal recurrente diseÃ±ada para aprender dependencias a largo plazo.\n",
    "\n",
    "### CaracterÃ­sticas:\n",
    "- **Lookback Window:** 30 dÃ­as (usa 30 valores pasados para predecir el siguiente)\n",
    "- **Arquitectura:** LSTM(64 unidades) â†’ Dense(1)\n",
    "- **NormalizaciÃ³n:** MinMaxScaler (0-1)\n",
    "- **Early Stopping:** Evita overfitting automÃ¡ticamente\n",
    "\n",
    "### Ventajas sobre ARIMA:\n",
    "- âœ… Captura patrones no lineales\n",
    "- âœ… Memoria a largo plazo\n",
    "- âœ… No requiere estacionariedad\n",
    "\n",
    "**Nota:** Usamos `epochs=5` para demostraciÃ³n rÃ¡pida (producciÃ³n: 50-100 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ§  Entrenando modelo LSTM...\")\n",
    "print(\"â³ Esto puede tardar 2-3 minutos dependiendo del hardware\\n\")\n",
    "\n",
    "# Entrenar modelo RNN (LSTM)\n",
    "model, scaler, rnn_metrics = train_rnn(\n",
    "    btc, \n",
    "    date_col='date', \n",
    "    target_col='price_usd', \n",
    "    model_type='LSTM',    # Alternativa: 'GRU'\n",
    "    lookback=30,          # Ventana de 30 dÃ­as\n",
    "    epochs=5,             # Bajo para demo (producciÃ³n: 50-100)\n",
    "    batch_size=32,\n",
    "    train_ratio=0.8\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š RESULTADOS LSTM\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE (Mean Absolute Error):  ${rnn_metrics['MAE']:,.2f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): ${rnn_metrics['RMSE']:,.2f}\")\n",
    "print(f\"\\nğŸ† Arquitectura: LSTM(64) â†’ Dense(1)\")\n",
    "print(f\"ğŸ“Š Lookback window: 30 dÃ­as\")\n",
    "\n",
    "# ComparaciÃ³n con ARIMA\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸ“Š COMPARACIÃ“N: ARIMA vs LSTM\")\n",
    "print(\"=\"*50)\n",
    "comparison = pd.DataFrame({\n",
    "    'Modelo': ['ARIMA', 'LSTM'],\n",
    "    'MAE': [arima_metrics['MAE'], rnn_metrics['MAE']],\n",
    "    'RMSE': [arima_metrics['RMSE'], rnn_metrics['RMSE']]\n",
    "})\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "best_model = 'ARIMA' if arima_metrics['MAE'] < rnn_metrics['MAE'] else 'LSTM'\n",
    "print(f\"\\nğŸ† Mejor modelo (menor MAE): {best_model}\")\n",
    "\n",
    "rnn_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24ecf79",
   "metadata": {},
   "source": [
    "## ğŸ“Š VisualizaciÃ³n de Clusters\n",
    "\n",
    "Graficamos los clusters en el espacio de features (daily_return vs roll_vol_30d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db354be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar datos para visualizaciÃ³n\n",
    "plot_df = dropna_df[features].copy()\n",
    "plot_df['KMeans'] = km_labels['label'].values\n",
    "plot_df['DBSCAN'] = db_labels['label'].values\n",
    "plot_df['Agglomerative'] = ag_labels['label'].values\n",
    "\n",
    "# Crear subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# K-Means\n",
    "scatter1 = axes[0].scatter(plot_df['daily_return'], plot_df['roll_vol_30d'], \n",
    "                           c=plot_df['KMeans'], cmap='viridis', alpha=0.6, s=20)\n",
    "axes[0].set_title(f'K-Means\\nSilhouette: {km_sil:.4f}', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Daily Return')\n",
    "axes[0].set_ylabel('Rolling Volatility 30D')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
    "\n",
    "# DBSCAN\n",
    "scatter2 = axes[1].scatter(plot_df['daily_return'], plot_df['roll_vol_30d'], \n",
    "                           c=plot_df['DBSCAN'], cmap='viridis', alpha=0.6, s=20)\n",
    "axes[1].set_title(f'DBSCAN\\nSilhouette: {db_sil:.4f}', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Daily Return')\n",
    "axes[1].set_ylabel('Rolling Volatility 30D')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter2, ax=axes[1], label='Cluster (-1=Outlier)')\n",
    "\n",
    "# Agglomerative\n",
    "scatter3 = axes[2].scatter(plot_df['daily_return'], plot_df['roll_vol_30d'], \n",
    "                           c=plot_df['Agglomerative'], cmap='viridis', alpha=0.6, s=20)\n",
    "axes[2].set_title(f'Agglomerative\\nSilhouette: {ag_sil:.4f}', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Daily Return')\n",
    "axes[2].set_ylabel('Rolling Volatility 30D')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter3, ax=axes[2], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… VisualizaciÃ³n completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ef69e",
   "metadata": {},
   "source": [
    "## ğŸ“ Conclusiones y Resultados Finales\n",
    "\n",
    "### ğŸ¯ Resumen del AnÃ¡lisis\n",
    "\n",
    "Este notebook demostrÃ³ la implementaciÃ³n completa de tÃ©cnicas avanzadas de Business Intelligence aplicadas a criptomonedas:\n",
    "\n",
    "#### 1. **Clustering**\n",
    "- âœ… Implementados 3 algoritmos: K-Means, DBSCAN, Agglomerative\n",
    "- âœ… EvaluaciÃ³n con Silhouette Score\n",
    "- âœ… IdentificaciÃ³n de patrones de mercado y outliers\n",
    "\n",
    "#### 2. **Series Temporales - ARIMA**\n",
    "- âœ… Modelo estadÃ­stico clÃ¡sico\n",
    "- âœ… ValidaciÃ³n temporal (80/20)\n",
    "- âœ… MÃ©tricas: MAE y RMSE\n",
    "\n",
    "#### 3. **Redes Neuronales - LSTM**\n",
    "- âœ… Deep Learning con TensorFlow/Keras\n",
    "- âœ… Arquitectura: LSTM(64) â†’ Dense(1)\n",
    "- âœ… Early Stopping para prevenir overfitting\n",
    "\n",
    "### ğŸ“Š Cumplimiento de Objetivos Sprint 2\n",
    "\n",
    "| Objetivo | Estado |\n",
    "|----------|--------|\n",
    "| Implementar anÃ¡lisis de series temporales | âœ… |\n",
    "| Identificar patrones y tendencias | âœ… |\n",
    "| ClusterizaciÃ³n (densidad, particionante, jerÃ¡rquico) | âœ… |\n",
    "| Modelos de predicciÃ³n (ARIMA, LSTM, GRU) | âœ… |\n",
    "| MÃ©tricas de evaluaciÃ³n | âœ… |\n",
    "| MÃ³dulos backend | âœ… |\n",
    "| Notebook ejecutado | âœ… |\n",
    "\n",
    "### ğŸš€ PrÃ³ximos Pasos (Sprint 3)\n",
    "- Dashboard interactivo con Streamlit\n",
    "- API REST con FastAPI\n",
    "- Backtesting y walk-forward validation\n",
    "- Grid search para optimizaciÃ³n de hiperparÃ¡metros"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
